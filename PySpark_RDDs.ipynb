{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark on Mac\n",
    "\n",
    "To install PySpark, I used this [tutorial](https://medium.com/@GalarnykMichael/install-spark-on-mac-pyspark-453f395f240b) that offers a complete guideline about how to configure and update PySpark driver environment variables adding lines to your ~/.bash_profile file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resilient Distributed Datasets (RDDs)\n",
    "\n",
    "RDDs are the backbone of Apache Spark. They perform calculations faster because the dataset is parallelized, it means, distributed or split into chuncks based on keys and executor nodes.  \n",
    "\n",
    "The transformations to the dataset only occur when the action is taken, optimizing the execution.\n",
    "\n",
    "Let's try an example of RDDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 million of 2D dots are randomly generated. A basic multiplication and substraction is applied to every coordinate and then we calculate the mean and standard deviation of every population of coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "TOTAL = 1000000\n",
    "dots = sc.parallelize([2.0 * np.random.random(2) - 1.0 for i in range(TOTAL)]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.43353363, 0.81139593]),\n",
       " array([0.75313286, 0.40509211]),\n",
       " array([-0.83095786, -0.62381484]),\n",
       " array([ 0.7889119 , -0.76342479]),\n",
       " array([ 0.52880978, -0.57605368]),\n",
       " array([0.33215834, 0.82674053]),\n",
       " array([-0.3594745 ,  0.41015793]),\n",
       " array([0.87670549, 0.21995188]),\n",
       " array([-0.58730223,  0.94808889]),\n",
       " array([-0.30174567, -0.5058061 ])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access to the first 10 elements on dots:\n",
    "dots.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the elements on dots:\n",
    "dots.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43353363, 0.81139593])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect firt line\n",
    "dots.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [ 0.0002259  -0.00015072]\n",
      "stdev: [0.57732011 0.57712783]\n"
     ]
    }
   ],
   "source": [
    "stats = dots.stats()\n",
    "print('Mean:', stats.mean())\n",
    "print('stdev:', stats.stdev())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Data Transformations\n",
    "\n",
    "\n",
    "What kind of transformations we can do? Mapping, filtering, joining, and transcoding are the operations that transform the values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(['a', 'b', 'c', 1, 1.1]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flat white', 2), ('latte', 1), ('pour over', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([('flat white', 1), ('latte', 4), ('pour over', 1), ('flat white', 3)]) \n",
    "sorted(rdd.countByKey().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sc.parallelize(['a', 'b', 'c', 'd', 'e', 'a', 'b']).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup of flat white',\n",
       " 'cup of capuccino',\n",
       " 'cup of latte',\n",
       " 'cup of tea',\n",
       " 'cup of matcha']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(['flat white', 'capuccino', 'latte', 'tea', 'matcha'])\n",
    "rdd.map(lambda x: 'cup of '+''.join(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.filter(lambda x: x % 2 == 0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flat white'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(['flat white', 'capuccino', 'latte', 'tea', 'matcha'])\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Using PySpark to perform Transformations and Actions on RDD](https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/?utm_source=blog&utm_medium=DataFramePySparkarticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sp.textFile(\"../pyspark/data/blogtexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Think of it for a moment – 1 Qunitillion = 1 Million Billion! Can you imagine how many drives / CDs / Blue-ray DVDs would be required to store them? It is difficult to imagine this scale of data generation even as a data science professional. While this pace of data generation is very exciting,  it has created entirely new set of challenges and has forced us to find new ways to handle Big Huge data effectively.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map and flatMap\n",
    "\n",
    "#### Q1: Convert all words in a rdd to lowercase and split the lines of a document using space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(text):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = rdd.map(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['think',\n",
       "  'of',\n",
       "  'it',\n",
       "  'for',\n",
       "  'a',\n",
       "  'moment',\n",
       "  '–',\n",
       "  '1',\n",
       "  'qunitillion',\n",
       "  '=',\n",
       "  '1',\n",
       "  'million',\n",
       "  'billion!',\n",
       "  'can',\n",
       "  'you',\n",
       "  'imagine',\n",
       "  'how',\n",
       "  'many',\n",
       "  'drives',\n",
       "  '/',\n",
       "  'cds',\n",
       "  '/',\n",
       "  'blue-ray',\n",
       "  'dvds',\n",
       "  'would',\n",
       "  'be',\n",
       "  'required',\n",
       "  'to',\n",
       "  'store',\n",
       "  'them?',\n",
       "  'it',\n",
       "  'is',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'imagine',\n",
       "  'this',\n",
       "  'scale',\n",
       "  'of',\n",
       "  'data',\n",
       "  'generation',\n",
       "  'even',\n",
       "  'as',\n",
       "  'a',\n",
       "  'data',\n",
       "  'science',\n",
       "  'professional.',\n",
       "  'while',\n",
       "  'this',\n",
       "  'pace',\n",
       "  'of',\n",
       "  'data',\n",
       "  'generation',\n",
       "  'is',\n",
       "  'very',\n",
       "  'exciting,',\n",
       "  'it',\n",
       "  'has',\n",
       "  'created',\n",
       "  'entirely',\n",
       "  'new',\n",
       "  'set',\n",
       "  'of',\n",
       "  'challenges',\n",
       "  'and',\n",
       "  'has',\n",
       "  'forced',\n",
       "  'us',\n",
       "  'to',\n",
       "  'find',\n",
       "  'new',\n",
       "  'ways',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'big',\n",
       "  'huge',\n",
       "  'data',\n",
       "  'effectively.'],\n",
       " []]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.flatMap(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think', 'of', 'it', 'for', 'a', 'moment', '–', '1', 'qunitillion', '=']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n",
    "#### Q2: Remove stopwords and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS.add('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd2.map(lambda x: re.sub('[^A-Za-z0-9]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think', 'of', 'it', 'for', 'a', 'moment', '', '1', 'qunitillion', '']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.filter(lambda x: x not in STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think',\n",
       " 'moment',\n",
       " '1',\n",
       " 'qunitillion',\n",
       " '1',\n",
       " 'million',\n",
       " 'billion',\n",
       " 'imagine',\n",
       " 'drives',\n",
       " 'cds']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupBy\n",
    "\n",
    "#### Q3: Group the words in rdd4 based on which letters they start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = rdd4.groupBy(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 227),\n",
       " ('m', 127),\n",
       " ('1', 23),\n",
       " ('q', 7),\n",
       " ('b', 63),\n",
       " ('i', 109),\n",
       " ('d', 233),\n",
       " ('c', 275),\n",
       " ('r', 187),\n",
       " ('s', 371),\n",
       " ('g', 20),\n",
       " ('p', 199),\n",
       " ('e', 88),\n",
       " ('n', 94),\n",
       " ('f', 118),\n",
       " ('w', 49),\n",
       " ('h', 63),\n",
       " ('u', 34),\n",
       " ('o', 67),\n",
       " ('a', 171)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, len(list(value))) for k, value in rdd5.take(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t',\n",
       "  ['think',\n",
       "   'typically',\n",
       "   'turns',\n",
       "   'terms',\n",
       "   'time',\n",
       "   'traditional',\n",
       "   'topic',\n",
       "   'table',\n",
       "   'terms',\n",
       "   'traditional',\n",
       "   'tough',\n",
       "   'task',\n",
       "   'temperature',\n",
       "   'time',\n",
       "   'typically',\n",
       "   'task',\n",
       "   'task',\n",
       "   'time',\n",
       "   'time',\n",
       "   'task',\n",
       "   'task',\n",
       "   'terms',\n",
       "   'time',\n",
       "   'task',\n",
       "   'task',\n",
       "   'time',\n",
       "   'tasks',\n",
       "   'times',\n",
       "   'times',\n",
       "   'traditional',\n",
       "   'tasks',\n",
       "   'terms',\n",
       "   'types',\n",
       "   'terms',\n",
       "   'tasks',\n",
       "   'traditional',\n",
       "   'talk',\n",
       "   'times',\n",
       "   'tasks',\n",
       "   'turn',\n",
       "   'terms',\n",
       "   'time',\n",
       "   'time',\n",
       "   'tasks',\n",
       "   'technologies',\n",
       "   'time',\n",
       "   'task',\n",
       "   'time',\n",
       "   'transactions',\n",
       "   'time',\n",
       "   'time',\n",
       "   'think',\n",
       "   'transformations',\n",
       "   'transformations',\n",
       "   'topic',\n",
       "   'talking',\n",
       "   'terminal',\n",
       "   'terms',\n",
       "   'type',\n",
       "   'transfers',\n",
       "   'tar',\n",
       "   'tar',\n",
       "   'tool',\n",
       "   'time',\n",
       "   'typing',\n",
       "   'typing',\n",
       "   'typing',\n",
       "   'typing',\n",
       "   'thread',\n",
       "   'time',\n",
       "   'time',\n",
       "   'transformations',\n",
       "   'talk',\n",
       "   'tolerant',\n",
       "   'transformations',\n",
       "   'things',\n",
       "   'types',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformations',\n",
       "   'task',\n",
       "   'task',\n",
       "   'types',\n",
       "   'type',\n",
       "   'transformation',\n",
       "   'tells',\n",
       "   'tuple',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'transformed',\n",
       "   'transformation',\n",
       "   'transformation',\n",
       "   'time',\n",
       "   'transformation',\n",
       "   'talk',\n",
       "   'table',\n",
       "   'tutorial',\n",
       "   'table',\n",
       "   'type',\n",
       "   'train',\n",
       "   'test',\n",
       "   'train',\n",
       "   'trueinferschema',\n",
       "   'true',\n",
       "   'test',\n",
       "   'trueinferschema',\n",
       "   'true',\n",
       "   'train',\n",
       "   'test',\n",
       "   'true',\n",
       "   'true',\n",
       "   'telling',\n",
       "   'type',\n",
       "   'true',\n",
       "   'type',\n",
       "   'types',\n",
       "   'train',\n",
       "   'tree',\n",
       "   'trainprintschema',\n",
       "   'train',\n",
       "   'trainhead10',\n",
       "   'train',\n",
       "   'traincount',\n",
       "   'train',\n",
       "   'test',\n",
       "   'trainnadropcounttestnadropanycount',\n",
       "   'train',\n",
       "   'test',\n",
       "   'techniques',\n",
       "   'transform',\n",
       "   'train',\n",
       "   'test',\n",
       "   'train',\n",
       "   'trainfillna1',\n",
       "   'test',\n",
       "   'testfillna1',\n",
       "   'traindescribeshow',\n",
       "   'train',\n",
       "   'trainselectuseridshow',\n",
       "   'train',\n",
       "   'test',\n",
       "   'train',\n",
       "   'test',\n",
       "   'trainselectproductiddistinctcount',\n",
       "   'testselectproductiddistinctcount',\n",
       "   'train',\n",
       "   'test',\n",
       "   'train',\n",
       "   'test',\n",
       "   'test',\n",
       "   'train',\n",
       "   'test',\n",
       "   'train',\n",
       "   'test',\n",
       "   'train',\n",
       "   'transforming',\n",
       "   'transform',\n",
       "   'transformation',\n",
       "   'train',\n",
       "   'transform',\n",
       "   'train',\n",
       "   'test',\n",
       "   'transform',\n",
       "   'train',\n",
       "   'test',\n",
       "   'transform',\n",
       "   'transformation',\n",
       "   'train1',\n",
       "   'test1',\n",
       "   'train1',\n",
       "   'test1',\n",
       "   'train1',\n",
       "   'train1show',\n",
       "   'train1',\n",
       "   'transformed',\n",
       "   'train',\n",
       "   'try',\n",
       "   'train1',\n",
       "   'transform',\n",
       "   'train1test1',\n",
       "   'transform',\n",
       "   'train1test1',\n",
       "   'train1test1',\n",
       "   'train1',\n",
       "   't1transformtrain1',\n",
       "   'test1',\n",
       "   't1transformtest1',\n",
       "   'transformed',\n",
       "   'train1',\n",
       "   'test1',\n",
       "   'train1show',\n",
       "   'train1',\n",
       "   'test1',\n",
       "   'train1',\n",
       "   'test1',\n",
       "   'transformed',\n",
       "   'transom',\n",
       "   'train1',\n",
       "   'test1',\n",
       "   'train1selectfeaturesshow',\n",
       "   'train1selectlabelshow',\n",
       "   'transforming',\n",
       "   'task',\n",
       "   'train1',\n",
       "   'traincv',\n",
       "   'testcv',\n",
       "   'train1',\n",
       "   'traincv',\n",
       "   'testcv',\n",
       "   'traincv',\n",
       "   'testcv',\n",
       "   'train1randomsplit07',\n",
       "   'traincv',\n",
       "   'testcv',\n",
       "   'testcv',\n",
       "   'testcv',\n",
       "   'train1',\n",
       "   'things',\n",
       "   'tutorials',\n",
       "   'time'])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, list(value)) for k, value in rdd5.take(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupByKey / reduceByKey \n",
    "\n",
    "#### Q4. Frecuency of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd6 = rdd4.map(lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd7 = rdd6.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('think', 2),\n",
       " ('moment', 1),\n",
       " ('1', 12),\n",
       " ('qunitillion', 1),\n",
       " ('million', 1),\n",
       " ('billion', 1),\n",
       " ('imagine', 4),\n",
       " ('drives', 1),\n",
       " ('cds', 1),\n",
       " ('blueray', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, len(list(value))) for key, value in rdd7.take(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd7_freq_of_words = rdd7.mapValues(sum).map(lambda x: (x[1],x[0])).sortByKey(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(91, 'spark'),\n",
       " (74, 'data'),\n",
       " (52, 'apache'),\n",
       " (48, 'rdd'),\n",
       " (27, 'need'),\n",
       " (22, 'dataframe'),\n",
       " (22, 'cluster'),\n",
       " (22, 'train'),\n",
       " (21, 'lets'),\n",
       " (21, 'method')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd7_freq_of_words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(91, 'spark'),\n",
       " (74, 'data'),\n",
       " (52, 'apache'),\n",
       " (48, 'rdd'),\n",
       " (27, 'need'),\n",
       " (22, 'dataframe'),\n",
       " (22, 'cluster'),\n",
       " (22, 'train'),\n",
       " (21, 'lets'),\n",
       " (21, 'method')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd6.reduceByKey(lambda x,y: x+y).map(lambda x:(x[1],x[0])).sortByKey(False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapPartitions\n",
    "\n",
    "mapPartitions is a map transformation running in different partitions of the RDD. For instances, if we are curious about the frequency of 10 specific words, it's possible count them in different partitions.\n",
    "\n",
    "#### Q5. Perform a task in different partitions of the RDD: Investigate the frequency of the following words: \n",
    "- spark\n",
    "- apache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a function with the task required and then, pass the function to the **mapPartitions** transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def func(iterator):\n",
    "    \n",
    "    counter = Counter(iterator)\n",
    "    return (counter['spark'], counter['apache'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the number of partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we increase the number of partitions applying the function **repartition** over the RDD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "repartrdd = rdd4.repartition(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of partitions again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartrdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the function to the mapPartitions -using the original RDD- performs the task in just one partition. **glom** function allows us inspect the data into every partition. We use this tool to compare the original output and others generated changing the number of partitions. In the first case, as we could expect, the output is a single array with the frecuency of every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[91, 52]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.mapPartitions(func).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for the new RDD with 6 partitions, we expect 6 outputs with two elements each one, corresponding to the frecuency of the pair of words searched in every partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 8], [15, 8], [15, 8], [20, 10], [16, 11], [13, 7]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartrdd.mapPartitions(func).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which function do we use to reduce the number of partitions? We can use **repartition** or **coalesce**. The first one does a full shuffle of the data and creates equal sized partitions of data. Instead, coalesce combine existint partitions to avoid a full shuffle, an expensive operation for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalescerdd = repartrdd.coalesce(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*coalesce* is the function to reduce the number of partitions. For this new RDD with 4 partitions, we expect 4 outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 8], [33, 17], [30, 16], [16, 11]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coalescerdd.mapPartitions(func).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6: How do we get a sample of a population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*sample* transformation has the following parameters:\n",
    "- withReplacement (bool)\n",
    "- fraction (float)\n",
    "- seed, random state (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_sample = rdd4.sample(False, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdd_sample.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2762"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdd4.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union/join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: Union of two RDD's. One with all the words starting with 'u' and another with the words ending with 'a'.\n",
    "#### Notes: union doesn't delete duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_words = rdd4.filter(lambda x: x[0] == 'e').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exciting',\n",
       " 'entirely',\n",
       " 'effectively',\n",
       " 'experience',\n",
       " 'efficient',\n",
       " 'emanating',\n",
       " 'efficiently',\n",
       " 'example',\n",
       " 'end',\n",
       " 'explain',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'examples',\n",
       " 'enables',\n",
       " 'executors',\n",
       " 'ends',\n",
       " 'evaluation',\n",
       " 'execute',\n",
       " 'entire',\n",
       " 'easiest',\n",
       " 'extract',\n",
       " 'extracted',\n",
       " 'editing',\n",
       " 'environment',\n",
       " 'editor',\n",
       " 'export',\n",
       " 'extent',\n",
       " 'exploring',\n",
       " 'elements',\n",
       " 'element',\n",
       " 'existing',\n",
       " 'external',\n",
       " 'earlier',\n",
       " 'executing',\n",
       " 'elegant',\n",
       " 'encode',\n",
       " 'extra',\n",
       " 'evaluate',\n",
       " 'error',\n",
       " 'evaluator',\n",
       " 'evaluatorevaluatepredictionsevaluatormetricnamemse']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_a = rdd4.filter(lambda x: x[-1] == 'a').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'phenomena',\n",
       " 'scala',\n",
       " 'california',\n",
       " 'java',\n",
       " 'ppawebupd8teamjava',\n",
       " 'metadata',\n",
       " 'scparallelizedata',\n",
       " 'gupta',\n",
       " 'lambda',\n",
       " 'rddmaplambda',\n",
       " 'trueinferschema',\n",
       " 'inferschema',\n",
       " 'printschema',\n",
       " 'schema',\n",
       " 'trainprintschema',\n",
       " 'fillna',\n",
       " 'comma',\n",
       " 'formula',\n",
       " 'rformula',\n",
       " 'extra']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = e_words.union(words_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length words starting with \"e\": 41\n",
      "Length words finishing with \"a\": 21\n",
      "Lenght union: 62\n"
     ]
    }
   ],
   "source": [
    "print('Length words starting with \"e\": {}'.format(len(e_words.collect())))\n",
    "print('Length words finishing with \"a\": {}'.format(len(words_a.collect())))     \n",
    "print('Lenght union: {}'.format(len(union.collect())))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: Joining two pair RDD's based on their key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = rdd6.sample(False, 0.2, 42).distinct()\n",
    "sample2 = rdd6.sample(False, 0.2, 21).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('think', 1),\n",
       " ('qunitillion', 1),\n",
       " ('1', 1),\n",
       " ('blueray', 1),\n",
       " ('difficult', 1),\n",
       " ('data', 1),\n",
       " ('generation', 1),\n",
       " ('find', 1),\n",
       " ('handle', 1),\n",
       " ('huge', 1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_samples = sample1.join(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('think', (1, 1)),\n",
       " ('qunitillion', (1, 1)),\n",
       " ('1', (1, 1)),\n",
       " ('huge', (1, 1)),\n",
       " ('offering', (1, 1)),\n",
       " ('based', (1, 1)),\n",
       " ('large', (1, 1)),\n",
       " ('read', (1, 1)),\n",
       " ('learning', (1, 1)),\n",
       " ('challenges', (1, 1))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_samples.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length sample 1: 335\n",
      "Length sample 2: 356\n",
      "Lenght joined samples: 166\n"
     ]
    }
   ],
   "source": [
    "print('Length sample 1: {}'.format(len(sample1.collect())))\n",
    "print('Length sample 2: {}'.format(len(sample2.collect())))     \n",
    "print('Lenght joined samples: {}'.format(len(joined_samples.collect())))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
