{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PySpark Mini-project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Storm events in US during 2019 are studied in the following analysis using the NOAA's National Weather Service Dataset available [here](https://www.ncdc.noaa.gov/stormevents/ftp.jsp). The folder **data** contains three csv files with event details, fatalities and location of every event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName(\"pysparkDataframes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStorm2019 = sc.read.format('csv')\\\n",
    "                .option('header', 'true')\\\n",
    "                .option('delimiter', ',')\\\n",
    "                .option('inferSchema', 'true')\\\n",
    "                .load('../pyspark/data/StormEvents_details-ftp_v1.0_d2019_c20200317.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFatalities2019 = sc.read.format('csv')\\\n",
    "                    .option('header', 'true')\\\n",
    "                    .option('delimiter', ',')\\\n",
    "                    .option('inferSchema', 'true')\\\n",
    "                    .load('../pyspark/data/StormEvents_fatalities-ftp_v1.0_d2019_c20200317.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLocations2019 = sc.read.format('csv')\\\n",
    "                    .option('header', 'true')\\\n",
    "                    .option('delimiter', ',')\\\n",
    "                    .option('inferSchema', 'true')\\\n",
    "                    .load('../pyspark/data/StormEvents_locations-ftp_v1.0_d2019_c20200317.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the schema of every dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BEGIN_YEARMONTH: integer (nullable = true)\n",
      " |-- BEGIN_DAY: integer (nullable = true)\n",
      " |-- BEGIN_TIME: integer (nullable = true)\n",
      " |-- END_YEARMONTH: integer (nullable = true)\n",
      " |-- END_DAY: integer (nullable = true)\n",
      " |-- END_TIME: integer (nullable = true)\n",
      " |-- EPISODE_ID: integer (nullable = true)\n",
      " |-- EVENT_ID: integer (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- STATE_FIPS: integer (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH_NAME: string (nullable = true)\n",
      " |-- EVENT_TYPE: string (nullable = true)\n",
      " |-- CZ_TYPE: string (nullable = true)\n",
      " |-- CZ_FIPS: integer (nullable = true)\n",
      " |-- CZ_NAME: string (nullable = true)\n",
      " |-- WFO: string (nullable = true)\n",
      " |-- BEGIN_DATE_TIME: string (nullable = true)\n",
      " |-- CZ_TIMEZONE: string (nullable = true)\n",
      " |-- END_DATE_TIME: string (nullable = true)\n",
      " |-- INJURIES_DIRECT: integer (nullable = true)\n",
      " |-- INJURIES_INDIRECT: integer (nullable = true)\n",
      " |-- DEATHS_DIRECT: integer (nullable = true)\n",
      " |-- DEATHS_INDIRECT: integer (nullable = true)\n",
      " |-- DAMAGE_PROPERTY: string (nullable = true)\n",
      " |-- DAMAGE_CROPS: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- MAGNITUDE: double (nullable = true)\n",
      " |-- MAGNITUDE_TYPE: string (nullable = true)\n",
      " |-- FLOOD_CAUSE: string (nullable = true)\n",
      " |-- CATEGORY: integer (nullable = true)\n",
      " |-- TOR_F_SCALE: string (nullable = true)\n",
      " |-- TOR_LENGTH: double (nullable = true)\n",
      " |-- TOR_WIDTH: double (nullable = true)\n",
      " |-- TOR_OTHER_WFO: string (nullable = true)\n",
      " |-- TOR_OTHER_CZ_STATE: string (nullable = true)\n",
      " |-- TOR_OTHER_CZ_FIPS: integer (nullable = true)\n",
      " |-- TOR_OTHER_CZ_NAME: string (nullable = true)\n",
      " |-- BEGIN_RANGE: integer (nullable = true)\n",
      " |-- BEGIN_AZIMUTH: string (nullable = true)\n",
      " |-- BEGIN_LOCATION: string (nullable = true)\n",
      " |-- END_RANGE: integer (nullable = true)\n",
      " |-- END_AZIMUTH: string (nullable = true)\n",
      " |-- END_LOCATION: string (nullable = true)\n",
      " |-- BEGIN_LAT: double (nullable = true)\n",
      " |-- BEGIN_LON: double (nullable = true)\n",
      " |-- END_LAT: double (nullable = true)\n",
      " |-- END_LON: double (nullable = true)\n",
      " |-- EPISODE_NARRATIVE: string (nullable = true)\n",
      " |-- EVENT_NARRATIVE: string (nullable = true)\n",
      " |-- DATA_SOURCE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfStorm2019.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FAT_YEARMONTH: integer (nullable = true)\n",
      " |-- FAT_DAY: integer (nullable = true)\n",
      " |-- FAT_TIME: integer (nullable = true)\n",
      " |-- FATALITY_ID: integer (nullable = true)\n",
      " |-- EVENT_ID: integer (nullable = true)\n",
      " |-- FATALITY_TYPE: string (nullable = true)\n",
      " |-- FATALITY_DATE: string (nullable = true)\n",
      " |-- FATALITY_AGE: integer (nullable = true)\n",
      " |-- FATALITY_SEX: string (nullable = true)\n",
      " |-- FATALITY_LOCATION: string (nullable = true)\n",
      " |-- EVENT_YEARMONTH: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFatalities2019.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEARMONTH: integer (nullable = true)\n",
      " |-- EPISODE_ID: integer (nullable = true)\n",
      " |-- EVENT_ID: integer (nullable = true)\n",
      " |-- LOCATION_INDEX: integer (nullable = true)\n",
      " |-- RANGE: double (nullable = true)\n",
      " |-- AZIMUTH: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- LAT2: integer (nullable = true)\n",
      " |-- LON2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfLocations2019.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes have a **registerTempTable attribute** that can be transform into spark sql to generate queries and save the results using **.write.saveAsTable(name_table)**. RDD's don't have this extension because they are not structured tables. \n",
    "\n",
    "Obs: **registerTempTable** is deprecated. Instead, use **createOrReplaceTempView**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStorm2019.createOrReplaceTempView('stormDetails_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Type of Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|          EVENT_TYPE|count(EVENT_TYPE)|\n",
      "+--------------------+-----------------+\n",
      "|   Thunderstorm Wind|            18617|\n",
      "|                Hail|             9013|\n",
      "|               Flood|             4943|\n",
      "|         Flash Flood|             4068|\n",
      "|      Winter Weather|             3800|\n",
      "|           High Wind|             3743|\n",
      "|        Winter Storm|             3312|\n",
      "|          Heavy Snow|             2844|\n",
      "|Marine Thundersto...|             2502|\n",
      "|             Tornado|             1727|\n",
      "|         Strong Wind|             1590|\n",
      "|          Heavy Rain|             1416|\n",
      "|                Heat|             1291|\n",
      "|Extreme Cold/Wind...|             1065|\n",
      "|             Drought|             1007|\n",
      "|            Blizzard|              852|\n",
      "|      Excessive Heat|              827|\n",
      "|        Frost/Freeze|              654|\n",
      "|           Dense Fog|              652|\n",
      "|     Cold/Wind Chill|              470|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                    EVENT_TYPE, \\\n",
    "                    COUNT(EVENT_TYPE) \\\n",
    "                    FROM stormDetails_table \\\n",
    "                    GROUP BY EVENT_TYPE \\\n",
    "                    ORDER BY COUNT(EVENT_TYPE) DESC').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 1851 to 2018, hurricanes seasons have hit different states across the country. The top hurricane states on record are Florida, Texas, North Carolina, Luisiana, South Carolina, Alabama, Georgia, Missisipi, New York and Massachussetts. Atlantic Hurricane season runs from June to November, mostly between August and September. From summer to fall, weather conditions become ideal to generate storms later, with cooler air and warm ocean water temperatures. Pacific Hurricane season runs from May to November (the Pacific Coast of the United State is affected by storms originated in Mexico in their roads to come back to the sea, toward Hawaii)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Number of episodes and events by STATE\n",
    "\n",
    "One episodes contains an unique or more events happening in different hours and days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|         STATE|NUMBER_EPISODES|\n",
      "+--------------+---------------+\n",
      "|         TEXAS|            536|\n",
      "|  SOUTH DAKOTA|            430|\n",
      "|    CALIFORNIA|            402|\n",
      "|      COLORADO|            331|\n",
      "|        KANSAS|            325|\n",
      "|      ILLINOIS|            299|\n",
      "|       WYOMING|            294|\n",
      "|      VIRGINIA|            283|\n",
      "|GULF OF MEXICO|            280|\n",
      "|     MINNESOTA|            279|\n",
      "|      NEBRASKA|            275|\n",
      "|          IOWA|            263|\n",
      "|      MISSOURI|            256|\n",
      "|  PENNSYLVANIA|            256|\n",
      "|      NEW YORK|            254|\n",
      "|NORTH CAROLINA|            247|\n",
      "|       FLORIDA|            243|\n",
      "|       MONTANA|            232|\n",
      "|     WISCONSIN|            232|\n",
      "|          OHIO|            229|\n",
      "+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                    STATE, \\\n",
    "                    COUNT(DISTINCT(EPISODE_ID)) AS NUMBER_EPISODES \\\n",
    "                    FROM stormDetails_table \\\n",
    "                    GROUP BY STATE ORDER BY COUNT(DISTINCT(EPISODE_ID))DESC').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The states with more episodes during 2019 were Texas, Soth Dakota, California, Colorado, Kansas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|         STATE|NUMBER_EVENTS|\n",
      "+--------------+-------------+\n",
      "|         TEXAS|         4338|\n",
      "|        KANSAS|         2672|\n",
      "|    CALIFORNIA|         2643|\n",
      "|  SOUTH DAKOTA|         2543|\n",
      "|      NEW YORK|         2514|\n",
      "|      VIRGINIA|         2398|\n",
      "|  PENNSYLVANIA|         2395|\n",
      "|          OHIO|         2279|\n",
      "|          IOWA|         2276|\n",
      "|      MISSOURI|         2159|\n",
      "|     MINNESOTA|         2126|\n",
      "|      NEBRASKA|         2088|\n",
      "|      ILLINOIS|         2084|\n",
      "|      OKLAHOMA|         1801|\n",
      "|      COLORADO|         1776|\n",
      "|     WISCONSIN|         1573|\n",
      "|      KENTUCKY|         1522|\n",
      "|NORTH CAROLINA|         1448|\n",
      "|       INDIANA|         1447|\n",
      "|       MONTANA|         1286|\n",
      "+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                    STATE, \\\n",
    "                    COUNT(DISTINCT(EVENT_ID)) AS NUMBER_EVENTS \\\n",
    "                    FROM stormDetails_table \\\n",
    "                    GROUP BY STATE ORDER BY COUNT(DISTINCT(EVENT_ID))DESC').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-------------+\n",
      "|          EVENT_TYPE|         STATE|NUMBER_EVENTS|\n",
      "+--------------------+--------------+-------------+\n",
      "|                Hail|         TEXAS|         1394|\n",
      "|   Thunderstorm Wind|  PENNSYLVANIA|         1245|\n",
      "|   Thunderstorm Wind|      VIRGINIA|         1199|\n",
      "|   Thunderstorm Wind|         TEXAS|         1047|\n",
      "|Marine Thundersto...|ATLANTIC NORTH|          997|\n",
      "|   Thunderstorm Wind|      NEW YORK|          903|\n",
      "|   Thunderstorm Wind|          OHIO|          891|\n",
      "|   Thunderstorm Wind|        KANSAS|          848|\n",
      "|                Hail|        KANSAS|          847|\n",
      "|   Thunderstorm Wind|NORTH CAROLINA|          791|\n",
      "|Marine Thundersto...|GULF OF MEXICO|          775|\n",
      "|               Flood|  SOUTH DAKOTA|          752|\n",
      "|   Thunderstorm Wind|       GEORGIA|          673|\n",
      "|   Thunderstorm Wind|      MISSOURI|          648|\n",
      "|                Hail|      NEBRASKA|          640|\n",
      "|   Thunderstorm Wind|SOUTH CAROLINA|          619|\n",
      "|   Thunderstorm Wind|       ALABAMA|          591|\n",
      "|   Thunderstorm Wind|      ILLINOIS|          587|\n",
      "|                Hail|      COLORADO|          580|\n",
      "|   Thunderstorm Wind|     TENNESSEE|          575|\n",
      "+--------------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                    EVENT_TYPE, \\\n",
    "                    STATE, \\\n",
    "                    COUNT(EVENT_TYPE) AS NUMBER_EVENTS \\\n",
    "                    FROM stormDetails_table \\\n",
    "                    GROUP BY STATE, EVENT_TYPE ORDER BY COUNT(EVENT_TYPE) DESC').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hails, thunderstorms and marine thonderstoms were the most common events in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Duration of events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we inspect the date information available in the stormDetails table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+-----------------+---------------+---------+----------+-------------+-------+--------+\n",
      "|EPISODE_ID|EVENT_ID|    STATE|       EVENT_TYPE|BEGIN_YEARMONTH|BEGIN_DAY|BEGIN_TIME|END_YEARMONTH|END_DAY|END_TIME|\n",
      "+----------+--------+---------+-----------------+---------------+---------+----------+-------------+-------+--------+\n",
      "|    137295|  824116|    TEXAS|      Flash Flood|         201905|        9|      1554|       201905|      9|    1830|\n",
      "|    140217|  843354|MINNESOTA|Thunderstorm Wind|         201907|       15|      1640|       201907|     15|    1641|\n",
      "|    142648|  861581|    TEXAS|Thunderstorm Wind|         201910|       20|      2223|       201910|     20|    2223|\n",
      "|    142648|  861584|    TEXAS|Thunderstorm Wind|         201910|       20|      2312|       201910|     20|    2312|\n",
      "|    142648|  861582|    TEXAS|Thunderstorm Wind|         201910|       20|      2236|       201910|     20|    2236|\n",
      "+----------+--------+---------+-----------------+---------------+---------+----------+-------------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                    EPISODE_ID, \\\n",
    "                    EVENT_ID, \\\n",
    "                    STATE, \\\n",
    "                    EVENT_TYPE, \\\n",
    "                    BEGIN_YEARMONTH, \\\n",
    "                    BEGIN_DAY, \\\n",
    "                    BEGIN_TIME,  \\\n",
    "                    END_YEARMONTH, \\\n",
    "                    END_DAY, \\\n",
    "                    END_TIME \\\n",
    "                    FROM stormDetails_table').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better datetime visualization results of the transformation of the begin and end dates as strings with format **yyyy-mm-dd hh-mm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------+--------------------+----------------+----------------+\n",
      "|EPISODE_ID|EVENT_ID|         STATE|          EVENT_TYPE|      BEGIN_DATE|        END_DATE|\n",
      "+----------+--------+--------------+--------------------+----------------+----------------+\n",
      "|    137295|  824116|         TEXAS|         Flash Flood| 2019-05-9 15:54| 2019-05-9 18:30|\n",
      "|    140217|  843354|     MINNESOTA|   Thunderstorm Wind|2019-07-15 16:40|2019-07-15 16:41|\n",
      "|    142648|  861581|         TEXAS|   Thunderstorm Wind|2019-10-20 22:23|2019-10-20 22:23|\n",
      "|    142648|  861584|         TEXAS|   Thunderstorm Wind|2019-10-20 23:12|2019-10-20 23:12|\n",
      "|    142648|  861582|         TEXAS|   Thunderstorm Wind|2019-10-20 22:36|2019-10-20 22:36|\n",
      "|    142648|  856504|         TEXAS|             Tornado|2019-10-20 20:48|2019-10-20 20:54|\n",
      "|    141212|  848333|       VERMONT|                Hail| 2019-09-4 12:29| 2019-09-4 12:29|\n",
      "|    141215|  848338|      NEW YORK|   Thunderstorm Wind|2019-09-26 15:54|2019-09-26 15:54|\n",
      "|    140688|  845760|ATLANTIC SOUTH|Marine Thundersto...|2019-09-13 18:38|2019-09-13 18:38|\n",
      "|    140688|  845762|ATLANTIC SOUTH|Marine Thundersto...|2019-09-13 19:15|2019-09-13 19:15|\n",
      "|    140688|  845764|ATLANTIC SOUTH|Marine Thundersto...|2019-09-13 19:38|2019-09-13 19:38|\n",
      "|    141232|  848441|       FLORIDA|         Rip Current|2019-09-30 17:40|2019-09-30 17:40|\n",
      "|    133946|  801726| WEST VIRGINIA|      Winter Weather|2019-01-29 12:00|2019-01-29 19:00|\n",
      "|    134106|  814097|      ARKANSAS|   Thunderstorm Wind|  2019-03-9 81:0|  2019-03-9 81:0|\n",
      "|    134106|  814096|      ARKANSAS|   Thunderstorm Wind|  2019-03-9 75:0|  2019-03-9 75:0|\n",
      "|    141237|  848459|ATLANTIC SOUTH|Marine Thundersto...|2019-09-30 18:14|2019-09-30 18:14|\n",
      "|    141237|  848462|ATLANTIC SOUTH|Marine Thundersto...|2019-09-30 20:15|2019-09-30 20:15|\n",
      "|    140062|  842668|GULF OF MEXICO|Marine Thundersto...| 2019-09-2 12:42| 2019-09-2 12:42|\n",
      "|    140067|  842699|GULF OF MEXICO|          Waterspout| 2019-09-6 14:53| 2019-09-6 14:56|\n",
      "|    141077|  847645|GULF OF MEXICO|Marine Thundersto...|2019-09-18 18:05|2019-09-18 18:05|\n",
      "+----------+--------+--------------+--------------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT \\\n",
    "                    EPISODE_ID, \\\n",
    "                    EVENT_ID, \\\n",
    "                    STATE, \\\n",
    "                    EVENT_TYPE, \\\n",
    "                    CONCAT(SUBSTRING(BEGIN_YEARMONTH, 1, 4), '-', \\\n",
    "                    SUBSTRING(BEGIN_YEARMONTH, 5, 2), '-', \\\n",
    "                    BEGIN_DAY, ' ', SUBSTRING(BEGIN_TIME, 1, 2), ':', SUBSTRING(BEGIN_TIME, 3, 2)) AS BEGIN_DATE, \\\n",
    "                    CONCAT(SUBSTRING(END_YEARMONTH, 1, 4), '-', \\\n",
    "                    SUBSTRING(END_YEARMONTH, 5, 2), '-', \\\n",
    "                    END_DAY, ' ', SUBSTRING(END_TIME, 1, 2), ':', SUBSTRING(END_TIME, 3, 2)) AS END_DATE \\\n",
    "                    FROM stormDetails_table\").show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table below, `DELTA_YEAR` and `DELTA_MONTH` are the differences between the begin/end years and months respectively. Both are extracted from `BEGIN_YEARMONTH` and `END_YEARMONTH` using the SQL function SUBSTRING. The same attribute is used to retrieve hours and minutes from `BEGIN_TIME` and `END_TIME`. `DELTA_DAYS` is compute directly from `BEGIN_DAY` and `END_DAY`.\n",
    "\n",
    "100 rows are displayed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------+--------------------+----------+-----------+---------+-----------+\n",
      "|EPISODE_ID|EVENT_ID|         STATE|          EVENT_TYPE|DELTA_YEAR|DELTA_MONTH|DELTA_DAY|DELTA_HOURS|\n",
      "+----------+--------+--------------+--------------------+----------+-----------+---------+-----------+\n",
      "|    137295|  824116|         TEXAS|         Flash Flood|         0|          0|        0|   2.600000|\n",
      "|    140217|  843354|     MINNESOTA|   Thunderstorm Wind|         0|          0|        0|   0.016667|\n",
      "|    142648|  861581|         TEXAS|   Thunderstorm Wind|         0|          0|        0|   0.000000|\n",
      "|    142648|  861584|         TEXAS|   Thunderstorm Wind|         0|          0|        0|   0.000000|\n",
      "|    142648|  861582|         TEXAS|   Thunderstorm Wind|         0|          0|        0|   0.000000|\n",
      "|    142648|  856504|         TEXAS|             Tornado|         0|          0|        0|   0.100000|\n",
      "|    141212|  848333|       VERMONT|                Hail|         0|          0|        0|   0.000000|\n",
      "|    141215|  848338|      NEW YORK|   Thunderstorm Wind|         0|          0|        0|   0.000000|\n",
      "|    140688|  845760|ATLANTIC SOUTH|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "|    140688|  845762|ATLANTIC SOUTH|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "|    140688|  845764|ATLANTIC SOUTH|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "|    141232|  848441|       FLORIDA|         Rip Current|         0|          0|        0|   0.000000|\n",
      "|    133946|  801726| WEST VIRGINIA|      Winter Weather|         0|          0|        0|   7.000000|\n",
      "|    134106|  814097|      ARKANSAS|   Thunderstorm Wind|         0|          0|        0|   0.000000|\n",
      "|    134106|  814096|      ARKANSAS|   Thunderstorm Wind|         0|          0|        0|   0.000000|\n",
      "|    141237|  848459|ATLANTIC SOUTH|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "|    141237|  848462|ATLANTIC SOUTH|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "|    140062|  842668|GULF OF MEXICO|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "|    140067|  842699|GULF OF MEXICO|          Waterspout|         0|          0|        0|   0.050000|\n",
      "|    141077|  847645|GULF OF MEXICO|Marine Thundersto...|         0|          0|        0|   0.000000|\n",
      "+----------+--------+--------------+--------------------+----------+-----------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                   EPISODE_ID, \\\n",
    "                   EVENT_ID, STATE, \\\n",
    "                   EVENT_TYPE, \\\n",
    "                   CAST(SUBSTRING(END_YEARMONTH, 1, 4) AS INT) - CAST(SUBSTRING(BEGIN_YEARMONTH, 1, 4) AS INT) AS DELTA_YEAR, \\\n",
    "                   CAST(SUBSTRING(END_YEARMONTH, 5, 2) AS INT) - CAST(SUBSTRING(BEGIN_YEARMONTH, 5, 2) AS INT) AS DELTA_MONTH, \\\n",
    "                   END_DAY - BEGIN_DAY AS DELTA_DAY, \\\n",
    "                   ((CAST(SUBSTRING(END_TIME, 1, 2) AS INT)*60 + CAST(SUBSTRING(END_TIME, 3, 2) AS INT)) - (CAST(SUBSTRING(BEGIN_TIME, 1, 2) AS INT)*60 + CAST(SUBSTRING(BEGIN_TIME, 3, 2) AS INT)))/60.0 AS DELTA_HOURS \\\n",
    "                   FROM stormDetails_table').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of events with a `DELTA_MONTH` upper than 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+----------+---------+-----------+\n",
      "|EPISODE_ID|EVENT_ID|STATE|EVENT_TYPE|DELTA_DAY|DELTA_HOURS|\n",
      "+----------+--------+-----+----------+---------+-----------+\n",
      "+----------+--------+-----+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                   EPISODE_ID, \\\n",
    "                   EVENT_ID, \\\n",
    "                   STATE, \\\n",
    "                   EVENT_TYPE, \\\n",
    "                   DELTA_DAY, \\\n",
    "                   DELTA_HOURS \\\n",
    "                   FROM (\\\n",
    "                        SELECT \\\n",
    "                            EPISODE_ID, \\\n",
    "                            EVENT_ID, \\\n",
    "                            STATE, \\\n",
    "                            EVENT_TYPE, \\\n",
    "                            CAST(SUBSTRING(END_YEARMONTH, 1, 4) AS INT) - CAST(SUBSTRING(BEGIN_YEARMONTH, 1, 4) AS INT) AS DELTA_YEAR, \\\n",
    "                            CAST(SUBSTRING(END_YEARMONTH, 5, 2) AS INT) - CAST(SUBSTRING(BEGIN_YEARMONTH, 5, 2) AS INT) AS DELTA_MONTH, \\\n",
    "                            END_DAY - BEGIN_DAY AS DELTA_DAY, \\\n",
    "                            ((CAST(SUBSTRING(END_TIME, 1, 2) AS INT)*60 + CAST(SUBSTRING(END_TIME, 3, 2) AS INT)) - (CAST(SUBSTRING(BEGIN_TIME, 1, 2) AS INT)*60 + CAST(SUBSTRING(BEGIN_TIME, 3, 2) AS INT)))/60.0 AS DELTA_HOURS \\\n",
    "                            FROM stormDetails_table \\\n",
    "                        ) \\\n",
    "                   WHERE DELTA_MONTH > 0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------+----------+---------------+-------------+---------+-------+--------------------+\n",
      "|EPISODE_ID|EVENT_ID|         STATE|EVENT_TYPE|BEGIN_YEARMONTH|END_YEARMONTH|BEGIN_DAY|END_DAY|EFFECTIVE_DELTA_DAYS|\n",
      "+----------+--------+--------------+----------+---------------+-------------+---------+-------+--------------------+\n",
      "|    140042|  842536|  SOUTH DAKOTA|     Flood|         201907|       201907|        1|     31|       30.0361111250|\n",
      "|    140042|  842537|  SOUTH DAKOTA|     Flood|         201907|       201907|        1|     31|       30.0361111250|\n",
      "|    141294|  848629|         IDAHO|  Wildfire|         201908|       201908|        1|     31|       30.0000000000|\n",
      "|    137101|  822737|      ILLINOIS|     Flood|         201904|       201904|        1|     30|       29.0500000000|\n",
      "|    138578|  833168|          IOWA|     Flood|         201906|       201906|        1|     30|       29.0500000000|\n",
      "|    138858|  835315|  SOUTH DAKOTA|     Flood|         201906|       201906|        1|     30|       29.0423611250|\n",
      "|    140042|  842538|  SOUTH DAKOTA|     Flood|         201907|       201907|        2|     31|       29.0416666667|\n",
      "|    143103|  860406|     WISCONSIN|     Flood|         201910|       201910|        2|     31|       29.0305555417|\n",
      "|    141673|  850670|  SOUTH DAKOTA|     Flood|         201908|       201908|        2|     31|       29.0013888750|\n",
      "|    142654|  856244|      MISSOURI|     Flood|         201910|       201910|        2|     30|       28.0472222083|\n",
      "|    141501|  849615|  SOUTH DAKOTA|     Flood|         201908|       201908|        3|     31|       28.0451388750|\n",
      "|    134184|  803619|      ARKANSAS|     Flood|         201901|       201901|        3|     31|       28.0131944583|\n",
      "|    141851|  851643|      KENTUCKY|   Drought|         201910|       201910|        1|     29|       28.0027777917|\n",
      "|    141851|  851641|      KENTUCKY|   Drought|         201910|       201910|        1|     29|       28.0027777917|\n",
      "|    141851|  851644|      KENTUCKY|   Drought|         201910|       201910|        1|     29|       28.0027777917|\n",
      "|    141851|  851642|      KENTUCKY|   Drought|         201910|       201910|        1|     29|       28.0027777917|\n",
      "|    138050|  829623|      MISSOURI|     Flood|         201906|       201906|        3|     30|       27.0361111250|\n",
      "|    141683|  850712|  SOUTH DAKOTA|     Flood|         201908|       201908|        3|     30|       27.0000000000|\n",
      "|    142866|  857284|    CALIFORNIA|  Wildfire|         201909|       201909|        4|     30|       26.0243055417|\n",
      "|    140255|  843538|        HAWAII|   Drought|         201908|       201908|        6|     31|       25.0430555417|\n",
      "|    143192|  858937|        HAWAII|   Drought|         201911|       201911|        5|     30|       25.0430555417|\n",
      "|    141937|  852015|      COLORADO|  Wildfire|         201909|       201909|        5|     30|       25.0361111250|\n",
      "|    138617|  833471|          IOWA|     Flood|         201904|       201904|        6|     30|       24.0493055417|\n",
      "|    138516|  833043|  SOUTH DAKOTA|     Flood|         201904|       201904|        6|     30|       24.0083333333|\n",
      "|    138504|  833041|     MINNESOTA|     Flood|         201904|       201904|        6|     30|       24.0083333333|\n",
      "|    138504|  833042|     MINNESOTA|     Flood|         201904|       201904|        6|     30|       24.0083333333|\n",
      "|    140042|  842539|  SOUTH DAKOTA|     Flood|         201907|       201907|        2|     26|       24.0076388750|\n",
      "|    140044|  842540|          IOWA|     Flood|         201907|       201907|        2|     26|       24.0076388750|\n",
      "|    138006|  831130|      ARKANSAS|     Flood|         201905|       201905|        3|     27|       24.0076388750|\n",
      "|    138006|  831678|      ARKANSAS|     Flood|         201905|       201905|        2|     26|       24.0000000000|\n",
      "|    138617|  833473|          IOWA|     Flood|         201904|       201904|        7|     30|       23.0500000000|\n",
      "|    138617|  833474|          IOWA|     Flood|         201904|       201904|        7|     30|       23.0500000000|\n",
      "|    138617|  833475|          IOWA|     Flood|         201904|       201904|        7|     30|       23.0500000000|\n",
      "|    142482|  855233|        HAWAII|   Drought|         201910|       201910|        8|     31|       23.0430555417|\n",
      "|    142073|  852999|    WASHINGTON|  Wildfire|         201908|       201908|        2|     25|       23.0402777917|\n",
      "|    140263|  843547|          UTAH|  Wildfire|         201908|       201908|        6|     29|       23.0312500000|\n",
      "|    138617|  833468|          IOWA|     Flood|         201904|       201904|        7|     30|       23.0013888750|\n",
      "|    138617|  833470|          IOWA|     Flood|         201904|       201904|        7|     30|       23.0013888750|\n",
      "|    139960|  842079|  SOUTH DAKOTA|     Flood|         201907|       201907|        9|     31|       22.0430555417|\n",
      "|    139960|  842080|  SOUTH DAKOTA|     Flood|         201907|       201907|        9|     31|       22.0430555417|\n",
      "|    139960|  842077|  SOUTH DAKOTA|     Flood|         201907|       201907|        9|     31|       22.0430555417|\n",
      "|    138006|  831679|      ARKANSAS|     Flood|         201905|       201905|        4|     26|       22.0284722083|\n",
      "|    135066|  809476|      ARKANSAS|     Flood|         201902|       201902|        6|     28|       22.0166666667|\n",
      "|    136684|  820066|      ARKANSAS|     Flood|         201904|       201904|        8|     30|       22.0076388750|\n",
      "|    135978|  822682|          IOWA|     Flood|         201904|       201904|        1|     23|       22.0048611250|\n",
      "|    140045|  842560|  SOUTH DAKOTA|     Flood|         201907|       201907|        9|     31|       22.0013888750|\n",
      "|    140343|  843882|        OREGON|  Wildfire|         201909|       201909|        5|     27|       22.0000000000|\n",
      "|    141833|  851354|     LOUISIANA|   Drought|         201910|       201910|        8|     29|       21.0138888750|\n",
      "|    141833|  851355|     LOUISIANA|   Drought|         201910|       201910|        8|     29|       21.0138888750|\n",
      "|    138866|  835272|      MICHIGAN|     Flood|         201902|       201902|        6|     27|       21.0138888750|\n",
      "|    143341|  860453| WEST VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860505|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143341|  860445| WEST VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143341|  859917| WEST VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860475|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143445|  860574|NORTH CAROLINA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860494|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143341|  860452| WEST VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860472|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860477|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860486|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143445|  860575|NORTH CAROLINA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860497|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860577|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860473|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860489|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860496|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    143429|  860465|      VIRGINIA|   Drought|         201910|       201910|        1|     22|       21.0069444583|\n",
      "|    140397|  844013|         IDAHO|  Wildfire|         201907|       201907|       10|     31|       21.0055555417|\n",
      "|    134123|  803157|      ILLINOIS|     Flood|         201902|       201902|        7|     28|       21.0048611250|\n",
      "|    141851|  851812|      KENTUCKY|   Drought|         201910|       201910|        1|     22|       21.0027777917|\n",
      "|    141851|  851649|      KENTUCKY|   Drought|         201910|       201910|        1|     22|       21.0027777917|\n",
      "|    141851|  851639|      KENTUCKY|   Drought|         201910|       201910|        1|     22|       21.0027777917|\n",
      "|    143753|  863131|    CALIFORNIA|  Wildfire|         201910|       201910|       10|     31|       21.0000000000|\n",
      "|    143067|  858350|    CALIFORNIA|  Wildfire|         201909|       201909|        4|     25|       21.0000000000|\n",
      "|    140045|  842750|  SOUTH DAKOTA|     Flood|         201907|       201907|        9|     29|       20.0548611250|\n",
      "|    140074|  842752|          IOWA|     Flood|         201907|       201907|        9|     29|       20.0548611250|\n",
      "|    140045|  842749|  SOUTH DAKOTA|     Flood|         201907|       201907|        9|     29|       20.0548611250|\n",
      "|    138050|  829956|      MISSOURI|     Flood|         201906|       201906|        2|     22|       20.0208333333|\n",
      "|    134123|  803177|      ILLINOIS|     Flood|         201902|       201902|        8|     28|       20.0083333333|\n",
      "|    143403|  860407|     WISCONSIN|     Flood|         201910|       201910|        7|     27|       20.0083333333|\n",
      "|    134251|  803923|       INDIANA|     Flood|         201902|       201902|        8|     28|       20.0083333333|\n",
      "|    134251|  803925|       INDIANA|     Flood|         201902|       201902|        8|     28|       20.0083333333|\n",
      "|    135066|  809474|      ARKANSAS|     Flood|         201902|       201902|        8|     28|       20.0055555417|\n",
      "|    134251|  803939|       INDIANA|     Flood|         201902|       201902|        8|     28|       20.0013888750|\n",
      "|    134251|  803944|       INDIANA|     Flood|         201902|       201902|        8|     28|       20.0013888750|\n",
      "|    134123|  803178|      ILLINOIS|     Flood|         201902|       201902|        8|     28|       20.0013888750|\n",
      "|    134119|  803053|      KENTUCKY|     Flood|         201902|       201902|        9|     28|       19.0500000000|\n",
      "|    134123|  803151|      ILLINOIS|     Flood|         201902|       201902|        9|     28|       19.0493055417|\n",
      "|    142549|  856541|  SOUTH DAKOTA|     Flood|         201909|       201909|       11|     30|       19.0451388750|\n",
      "|    134119|  803096|      KENTUCKY|     Flood|         201902|       201902|        9|     28|       19.0437500000|\n",
      "|    142613|  856128|  SOUTH DAKOTA|     Flood|         201909|       201909|       11|     30|       19.0437500000|\n",
      "|    137388|  824897|        HAWAII|   Drought|         201906|       201906|       11|     30|       19.0430555417|\n",
      "|    137301|  824126|     LOUISIANA|     Flood|         201905|       201905|       12|     31|       19.0375000000|\n",
      "|    134251|  803914|       INDIANA|     Flood|         201902|       201902|        9|     28|       19.0291666667|\n",
      "|    134251|  803911|       INDIANA|     Flood|         201902|       201902|        9|     28|       19.0291666667|\n",
      "|    142549|  856545|  SOUTH DAKOTA|     Flood|         201909|       201909|       11|     30|       19.0152777917|\n",
      "|    142686|  856547|          IOWA|     Flood|         201909|       201909|       11|     30|       19.0152777917|\n",
      "|    142549|  856546|  SOUTH DAKOTA|     Flood|         201909|       201909|       11|     30|       19.0152777917|\n",
      "|    142549|  855790|  SOUTH DAKOTA|     Flood|         201909|       201909|       11|     30|       19.0138888750|\n",
      "+----------+--------+--------------+----------+---------------+-------------+---------+-------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT \\\n",
    "                   B.EPISODE_ID, \\\n",
    "                   B.EVENT_ID, \\\n",
    "                   B.STATE, \\\n",
    "                   B.EVENT_TYPE, \\\n",
    "                   B.BEGIN_YEARMONTH, \\\n",
    "                   B.END_YEARMONTH, \\\n",
    "                   B.BEGIN_DAY, \\\n",
    "                   B.END_DAY, \\\n",
    "                   B.EFFECTIVE_DELTA_DAYS \\\n",
    "                   FROM ( \\\n",
    "                       SELECT \\\n",
    "                           A.EPISODE_ID, \\\n",
    "                           A.EVENT_ID, \\\n",
    "                           A.STATE, \\\n",
    "                           A.EVENT_TYPE, \\\n",
    "                           A.BEGIN_YEARMONTH, \\\n",
    "                           A.END_YEARMONTH, \\\n",
    "                           A.BEGIN_DAY, \\\n",
    "                           A.END_DAY, \\\n",
    "                           CASE WHEN A.DELTA_HOURS IS NOT NULL THEN A.DELTA_DAY + A.DELTA_HOURS/24.0 ELSE A.DELTA_DAY END AS EFFECTIVE_DELTA_DAYS \\\n",
    "                           FROM (\\\n",
    "                                SELECT \\\n",
    "                                   EPISODE_ID, \\\n",
    "                                   EVENT_ID, \\\n",
    "                                   STATE, \\\n",
    "                                   EVENT_TYPE, \\\n",
    "                                   BEGIN_YEARMONTH, \\\n",
    "                                   END_YEARMONTH, \\\n",
    "                                   BEGIN_DAY, \\\n",
    "                                   END_DAY, \\\n",
    "                                   END_DAY - BEGIN_DAY AS DELTA_DAY, \\\n",
    "                                   ABS((CAST(SUBSTRING(END_TIME, 1, 2) AS INT) + CAST(SUBSTRING(END_TIME, 3, 2) AS INT)) - (CAST(SUBSTRING(BEGIN_TIME, 1, 2) AS INT) + CAST(SUBSTRING(BEGIN_TIME, 3, 2) AS INT)))/60.0 AS DELTA_HOURS \\\n",
    "                                   FROM stormDetails_table \\\n",
    "                                   WHERE CAST(END_TIME AS INT) > 0 AND CAST(BEGIN_TIME AS INT) > 0 \\\n",
    "                                ) AS A \\\n",
    "                    ) AS B \\\n",
    "                    ORDER BY B.EFFECTIVE_DELTA_DAYS DESC').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INJURIES_DIRECT: integer (nullable = true)\n",
    "#  |-- INJURIES_INDIRECT: integer (nullable = true)\n",
    "#  |-- DEATHS_DIRECT: integer (nullable = true)\n",
    "#  |-- DEATHS_INDIRECT: integer (nullable = true)\n",
    "#  |-- DAMAGE_PROPERTY: string (nullable = true)\n",
    "#  |-- DAMAGE_CROPS: string (nullable = true)\n",
    "#  |-- SOURCE: string (nullable = true)\n",
    "#  |-- MAGNITUDE: double (nullable = true)\n",
    "#  |-- MAGNITUDE_TYPE: string (nullable = true)\n",
    "#  |-- FLOOD_CAUSE: string (nullable = true)\n",
    "#  |-- CATEGORY: integer (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stormPandas = dfStorm2019.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
